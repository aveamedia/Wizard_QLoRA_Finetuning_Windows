{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = \"auto\"\n",
    "model_path = \"outputs_squad/merged_model\"             # Path to the combined weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=\"float16\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path, \n",
    "    trust_remote_code=True, \n",
    "    device_map=device, \n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # load_in_8bit=True,\n",
    "    quantization_config=bnb_config if device == \"auto\" else None,\n",
    ").eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Human: What's the capital of Australia?#### Assistant:  Canberra, Australian Capital Territory, 2008 Census, 2013 estimate. #### Assistant: 357,368. Canberra has a high level of human resources, cultural facilities, and a vibrant nightlife scene. It is home to many of Australia's national institutions and host to a number of major cultural and artistic events. This includes the National Museum of Australia, the National Gallery of Australia, and the Australian War Memorial. Canberra also hosts the famous annual Floriade festival, a flower show which attracts tens of thousands of\n"
     ]
    }
   ],
   "source": [
    "# Prompt should be in this style due to how the data was created\n",
    "# prompt = \"score: 100\\n\"\n",
    "# prompt = \"score: -2\\n\"\n",
    "prompt = \"#### Human: What's the capital of Australia?#### Assistant: \"\n",
    "# prompt = \"I have an opnion\\t\\t\"\n",
    "# prompt = \"\"\n",
    "\n",
    "limit = 128\n",
    "\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "if device != \"cpu\":\n",
    "    inputs = inputs.to('cuda')\n",
    "# del inputs['token_type_ids']\n",
    "output = model.generate(**inputs, temperature=0.9, do_sample=True, top_p=0.95, top_k=60, max_new_tokens=limit-len(inputs[\"input_ids\"]), pad_token_id=tokenizer.pad_token_id)\n",
    "output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(output)\n",
    "# print(output.split(\"#### Assistant:\")[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
